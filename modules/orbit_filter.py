import os
from pathlib import Path
import argparse
import numpy as np
import lpips
import cv2
from PIL import Image
from tqdm import tqdm
import torchvision.transforms as T
import torch
import shutil

# -----------------------------
# ê¸°ë³¸ ì„¤ì • (CPU ê³ ì •) - ì›ë³¸ ìœ ì§€
# -----------------------------
DEVICE = "cpu"
LPIPS_DUP_THRESH = 0.40   # ì¤‘ë³µ íŒë‹¨ ê¸°ì¤€
SHARP_THRESH = 20.0       # íë¦¼ íŒë‹¨ ê¸°ì¤€
MIN_KEEP = 18             # ìµœì†Œ ë³´ì¡´ ì´ë¯¸ì§€ ìˆ˜

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜ - ì›ë³¸ ìœ ì§€
# -----------------------------
def load_image(path):
    return Image.open(path).convert("RGB")

def save_image(img, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    img.save(path)

def pil_to_tensor(img):
    transform = T.Compose([
        T.Resize((256, 256)),
        T.ToTensor(),
        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    return transform(img).unsqueeze(0).to(DEVICE)

def compute_lpips(model, a_pil, b_pil):
    a = pil_to_tensor(a_pil)
    b = pil_to_tensor(b_pil)
    with torch.no_grad():
        return float(model(a, b).cpu().numpy().squeeze())

def compute_sharpness(img_pil):
    arr = np.array(img_pil.convert("L"))
    return float(cv2.Laplacian(arr, cv2.CV_64F).var())

# -----------------------------
# Filtering Logic - ì›ë³¸ ìœ ì§€
# -----------------------------
def simple_filtering(images, lpips_model):
    kept = []
    
    # ì›ë³¸ íŒŒì¼ëª… ë³´ì¡´ì„ ìœ„í•´ ì¸ë±ìŠ¤ ëŒ€ì‹  ì›ë³¸ ë¦¬ìŠ¤íŠ¸ì™€ ë§¤í•‘í•˜ë©´ ì¢‹ì§€ë§Œ,
    # ì—¬ê¸°ì„œëŠ” ìˆœì„œëŒ€ë¡œ í•„í„°ë§í•¨
    for img in tqdm(images, desc="  Filtering", leave=False):
        # 1) íë¦¼ ì²´í¬
        sharp = compute_sharpness(img)
        if sharp < SHARP_THRESH:
            continue

        # 2) ì¤‘ë³µ ì²´í¬
        is_dup = any(compute_lpips(lpips_model, img, k) < LPIPS_DUP_THRESH for k in kept)
        if is_dup:
            continue

        kept.append(img)

    # ìµœì†Œ ë³´ì¡´ ê°œìˆ˜ ê°•ì œ
    if len(kept) < MIN_KEEP:
        print(f"  [WARN] Too many filtered ({len(kept)}) -> Keeping first {MIN_KEEP} images")
        kept = images[:MIN_KEEP]

    return kept

# -----------------------------
# Main Process - ê²½ë¡œ ë° íƒ€ê²Ÿ ì„¤ì • ìˆ˜ì •
# -----------------------------
def main():
    parser = argparse.ArgumentParser()
    # ì‰˜ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë°›ì•„ì˜¬ ì¸ìë“¤
    parser.add_argument("--input_dir", type=str, required=True, help="Path to input frames")
    parser.add_argument("--output_dir", type=str, required=True, help="Path to save filtered images")
    parser.add_argument("--scene_name", type=str, required=False, help="Specific scene name to process (e.g., shark)")
    args = parser.parse_args()

    input_root = args.input_dir
    output_root = args.output_dir
    target_scene = args.scene_name

    print(f"ğŸ“‚ Input: {input_root}")
    print(f"ğŸ“‚ Output: {output_root}")
    if target_scene:
        print(f"ğŸ¯ Target Scene: {target_scene}")

    if not os.path.exists(input_root):
        print("âŒ Input directory not found. Please run Step 2 first.")
        return

    # LPIPS ëª¨ë¸ ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ë¡œë“œ)
    print("-> Loading LPIPS model...")
    torch.backends.mkldnn.enabled = False
    lpips_model = lpips.LPIPS(net="alex").to(DEVICE)

    # ê°ì²´ë³„ í´ë” ìˆœíšŒ (shark, dino ...)
    scene_dirs = sorted([d for d in Path(input_root).iterdir() if d.is_dir()])
    
    if not scene_dirs:
        print("âŒ No scene directories found inside input root.")
        return

    for scene_dir in scene_dirs:
        current_scene_name = scene_dir.name
        
        # [ê²€ì¦ëœ ìˆ˜ì •] íƒ€ê²Ÿ ì´ë¦„ì´ ì£¼ì–´ì¡Œë‹¤ë©´, ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” í´ë”ë§Œ ì²˜ë¦¬
        if target_scene and current_scene_name != target_scene:
            continue

        print(f"\nğŸš€ Processing Scene: {current_scene_name}")

        output_dir = os.path.join(output_root, current_scene_name)
        os.makedirs(output_dir, exist_ok=True)

        # ì´ë¯¸ì§€ ë¡œë“œ
        image_paths = sorted([
            str(p) for p in scene_dir.glob("*") 
            if p.suffix.lower() in [".jpg", ".jpeg", ".png"]
        ])

        if not image_paths:
            print(f"  [Skip] No images in {current_scene_name}")
            continue

        print(f"  -> Loaded {len(image_paths)} images")
        images = [load_image(p) for p in image_paths]

        # í•„í„°ë§ ìˆ˜í–‰
        kept = simple_filtering(images, lpips_model)

        # ì €ì¥ (íŒŒì¼ëª…ì€ 00000.png í¬ë§·ìœ¼ë¡œ ì¬ì •ë ¬)
        for i, img in enumerate(kept):
            save_path = os.path.join(output_dir, f"{i:05d}.png")
            save_image(img, save_path)

        print(f"  âœ… Saved {len(kept)} images to {output_dir}")

if __name__ == "__main__":
    main()